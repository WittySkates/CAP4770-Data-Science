{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions Near Bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `C:\\Users\\conno\\.julia\\environments\\v1.5\\Project.toml`\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `C:\\Users\\conno\\.julia\\environments\\v1.5\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `C:\\Users\\conno\\.julia\\environments\\v1.5\\Project.toml`\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `C:\\Users\\conno\\.julia\\environments\\v1.5\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `C:\\Users\\conno\\.julia\\environments\\v1.5\\Project.toml`\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `C:\\Users\\conno\\.julia\\environments\\v1.5\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `C:\\Users\\conno\\.julia\\environments\\v1.5\\Project.toml`\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `C:\\Users\\conno\\.julia\\environments\\v1.5\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `C:\\Users\\conno\\.julia\\environments\\v1.5\\Project.toml`\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `C:\\Users\\conno\\.julia\\environments\\v1.5\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `C:\\Users\\conno\\.julia\\environments\\v1.5\\Project.toml`\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `C:\\Users\\conno\\.julia\\environments\\v1.5\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `C:\\Users\\conno\\.julia\\environments\\v1.5\\Project.toml`\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `C:\\Users\\conno\\.julia\\environments\\v1.5\\Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"RDatasets\")\n",
    "Pkg.add(\"ScikitLearn\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"CSV\")\n",
    "Pkg.add(\"Suppressor\")\n",
    "Pkg.add(\"PyCall\")\n",
    "Pkg.add(\"PrettyTables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RDatasets: dataset\n",
    "using ScikitLearn\n",
    "using DataFrames\n",
    "using CSV\n",
    "using ScikitLearn.GridSearch: GridSearchCV\n",
    "using Suppressor\n",
    "using PyCall\n",
    "using PrettyTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ScikitLearn: CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant GaussianNB. This may fail, cause incorrect answers, or produce other errors.\n",
      "WARNING: redefinition of constant DecisionTreeClassifier. This may fail, cause incorrect answers, or produce other errors.\n",
      "WARNING: redefinition of constant SVC. This may fail, cause incorrect answers, or produce other errors.\n",
      "WARNING: redefinition of constant LinearSVC. This may fail, cause incorrect answers, or produce other errors.\n",
      "WARNING: redefinition of constant MLPClassifier. This may fail, cause incorrect answers, or produce other errors.\n",
      "WARNING: redefinition of constant OneHotEncoder. This may fail, cause incorrect answers, or produce other errors.\n",
      "WARNING: redefinition of constant confusion_matrix. This may fail, cause incorrect answers, or produce other errors.\n",
      "WARNING: redefinition of constant StandardScaler. This may fail, cause incorrect answers, or produce other errors.\n",
      "┌ Warning: Module pipeline has been ported to Julia - try `import ScikitLearn: Pipelines` instead\n",
      "└ @ ScikitLearn.Skcore C:\\Users\\conno\\.julia\\packages\\ScikitLearn\\NJwUf\\src\\Skcore.jl:179\n",
      "WARNING: redefinition of constant make_pipeline. This may fail, cause incorrect answers, or produce other errors.\n",
      "WARNING: redefinition of constant PCA. This may fail, cause incorrect answers, or produce other errors.\n",
      "WARNING: redefinition of constant VarianceThreshold. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    }
   ],
   "source": [
    "@sk_import naive_bayes: GaussianNB;\n",
    "@sk_import tree: DecisionTreeClassifier;\n",
    "@sk_import svm: SVC;\n",
    "@sk_import svm: LinearSVC;\n",
    "@sk_import neural_network: MLPClassifier;\n",
    "@sk_import preprocessing: OneHotEncoder;\n",
    "@sk_import metrics: confusion_matrix;\n",
    "@sk_import preprocessing: StandardScaler;\n",
    "@sk_import pipeline: make_pipeline;\n",
    "@sk_import decomposition: PCA;\n",
    "@sk_import feature_selection: VarianceThreshold;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib = pyimport(\"joblib\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CSV.File(\"car\\\\car.data\"; header=[\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"], types=[String, String, String, String, String, String, String]) |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = convert(Array, df[!, [:buying, :maint, :doors, :persons, :lug_boot, :safety]]);\n",
    "y = convert(Array, df[!, :class]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder();\n",
    "onehot_encoded = onehot_encoder.fit_transform(X);\n",
    "onehot_encoded = onehot_encoded.toarray();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = CrossValidation.train_test_split(onehot_encoded, y, test_size=0.30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayesian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car Data Naive Bayesian Classifier Training Time (Seconds): 0.0013208\n"
     ]
    }
   ],
   "source": [
    "model_baye_car_train_time = @elapsed begin\n",
    "model_baye_car = GaussianNB();\n",
    "model_baye_car.fit(X_train, y_train);\n",
    "end;\n",
    "println(\"Car Data Naive Bayesian Classifier Training Time (Seconds): \", model_baye_car_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car Data Naive Bayesian Classifier Size (Bytes): 2127\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model_baye_car, \"model_baye_car.pkl\")\n",
    "model_baye_car_size = stat(\"model_baye_car.pkl\").size\n",
    "println(\"Car Data Naive Bayesian Classifier Size (Bytes): \", model_baye_car_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car Data Naive Bayesian Classifier Accuracy (Testing): 81.11753371868978%\n",
      "Car Data Naive Bayesian Classifier Testing Time (Seconds): 0.0007432\n",
      "Car Data Naive Bayesian Classifier Accuracy (Training): 79.90074441687345%\n"
     ]
    }
   ],
   "source": [
    "model_baye_car_test_time = @elapsed begin\n",
    "model_baye_car_score_test = model_baye_car.score(X_test, y_test);\n",
    "end\n",
    "model_baye_car_score_train = model_baye_car.score(X_train, y_train);\n",
    "\n",
    "println(\"Car Data Naive Bayesian Classifier Accuracy (Testing): \", model_baye_car_score_test*100,\"%\")\n",
    "println(\"Car Data Naive Bayesian Classifier Testing Time (Seconds): \", model_baye_car_test_time)\n",
    "println(\"Car Data Naive Bayesian Classifier Accuracy (Training): \", model_baye_car_score_train*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: Dict{Symbol,Any}(:max_depth => 10)\n"
     ]
    }
   ],
   "source": [
    "# Find best parameters\n",
    "\n",
    "parameters = Dict(:max_depth => 1:1:20);\n",
    "gridsearch = GridSearchCV(DecisionTreeClassifier(), parameters);\n",
    "fit!(gridsearch, X_train, y_train);\n",
    "println(\"Best parameters: $(gridsearch.best_params_)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car Data Decision Tree Classifier Training Time (Seconds): 0.0014408\n"
     ]
    }
   ],
   "source": [
    "model_decision_car_train_time = @elapsed begin\n",
    "model_decision_car = DecisionTreeClassifier(max_depth = gridsearch.best_params_[:max_depth]);\n",
    "model_decision_car.fit(X_train, y_train);\n",
    "end\n",
    "println(\"Car Data Decision Tree Classifier Training Time (Seconds): \", model_decision_car_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car Data Decision Tree Classifier Model Size (Bytes): 13665\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model_decision_car, \"model_decision_car.pkl\")\n",
    "model_decision_car_size = stat(\"model_decision_car.pkl\").size\n",
    "println(\"Car Data Decision Tree Classifier Model Size (Bytes): \", model_decision_car_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car Data Decision Tree Classifier Accuracy (Testing): 92.8709055876686%\n",
      "Car Data Decision Tree Classifier Testing Time (Seconds): 0.000576501\n",
      "Car Data Decision Tree Classifier Accuracy (Training): 98.26302729528535%\n"
     ]
    }
   ],
   "source": [
    "model_decision_car_test_time = @elapsed  begin\n",
    "model_decision_car_score_test = model_decision_car.score(X_test, y_test);\n",
    "end\n",
    "model_decision_car_score_train = model_decision_car.score(X_train, y_train);\n",
    "println(\"Car Data Decision Tree Classifier Accuracy (Testing): \", model_decision_car_score_test*100,\"%\")\n",
    "println(\"Car Data Decision Tree Classifier Testing Time (Seconds): \", model_decision_car_test_time)\n",
    "println(\"Car Data Decision Tree Classifier Accuracy (Training): \", model_decision_car_score_train*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vecor Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best parameters\n",
    "\n",
    "# parameters = Dict(:kernel => [\"linear\", \"rbf\"], :gamma => [\"auto\", \"scale\"], :C => 1:5:50);\n",
    "# @suppress begin\n",
    "# gridsearch = GridSearchCV(SVC(), parameters);\n",
    "# fit!(gridsearch, X_train, y_train);\n",
    "# end\n",
    "# println(\"Best parameters: $(gridsearch.best_params_)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car Data Support Vector Machine Training Time (Seconds): 0.041693201\n"
     ]
    }
   ],
   "source": [
    "model_svm_car_train_time = @elapsed begin\n",
    "model_svm_car = make_pipeline(StandardScaler(), SVC(gamma = \"scale\", kernel = \"rbf\", C = 6));\n",
    "model_svm_car.fit(X_train, y_train);\n",
    "end\n",
    "println(\"Car Data Support Vector Machine Training Time (Seconds): \", model_svm_car_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car Data Support Vector Machine Model Size (Bytes): 117902\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model_svm_car, \"model_svm_car.pkl\")\n",
    "model_svm_car_size = stat(\"model_svm_car.pkl\").size\n",
    "println(\"Car Data Support Vector Machine Model Size (Bytes): \", model_svm_car_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car Data Support Vector Machine Accuracy (Testing): 99.22928709055877%\n",
      "Car Data Support Vector Machine Testing Time (Seconds): 0.0224784\n",
      "Car Data Support Vector Machine Accuracy (Training): 100.0%\n"
     ]
    }
   ],
   "source": [
    "model_svm_car_test_time = @elapsed begin\n",
    "model_svm_car_score_test = model_svm_car.score(X_test, y_test);\n",
    "end\n",
    "model_svm_car_score_train = model_svm_car.score(X_train, y_train);\n",
    "\n",
    "println(\"Car Data Support Vector Machine Accuracy (Testing): \", model_svm_car_score_test*100,\"%\")\n",
    "println(\"Car Data Support Vector Machine Testing Time (Seconds): \", model_svm_car_test_time)\n",
    "println(\"Car Data Support Vector Machine Accuracy (Training): \", model_svm_car_score_train*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nerual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best parameters\n",
    "\n",
    "# parameters = Dict(:activation => [\"tanh\", \"relu\"], :alpha => 0.0001:0.0001:0.0004, :hidden_layer_sizes => 200:50:500);\n",
    "# @suppress begin\n",
    "# gridsearch = GridSearchCV(MLPClassifier(), parameters);\n",
    "# fit!(gridsearch, X_train, y_train)\n",
    "# end\n",
    "# println(\"Best parameters: $(gridsearch.best_params_)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car MLP Training Time (Seconds): 2.2297599\n"
     ]
    }
   ],
   "source": [
    "model_mlp_car_train_time = @elapsed begin\n",
    "model_mlp_car = MLPClassifier(alpha = 0.0001, activation = \"relu\", hidden_layer_sizes = 400, max_iter=300);\n",
    "model_mlp_car.fit(X_train, y_train);\n",
    "end\n",
    "println(\"Car MLP Training Time (Seconds): \", model_mlp_car_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car Data MLP Model Size (Bytes): 343098\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model_mlp_car, \"model_mlp_car.pkl\")\n",
    "model_mlp_car_size = stat(\"model_mlp_car.pkl\").size\n",
    "println(\"Car Data MLP Model Size (Bytes): \", model_mlp_car_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car Data MLP Accuracy (Testing): 99.42196531791907%\n",
      "Car MLP Machine Testing Time (Seconds): 0.0022574\n",
      "Car Data MLP Accuracy (Training): 100.0%\n"
     ]
    }
   ],
   "source": [
    "model_mlp_car_test_time = @elapsed begin\n",
    "model_mlp_car_score_test = model_mlp_car.score(X_test, y_test);\n",
    "end\n",
    "model_mlp_car_score_train = model_mlp_car.score(X_train, y_train);\n",
    "\n",
    "println(\"Car Data MLP Accuracy (Testing): \", model_mlp_car_score_test*100,\"%\")\n",
    "println(\"Car MLP Machine Testing Time (Seconds): \", model_mlp_car_test_time)\n",
    "println(\"Car Data MLP Accuracy (Training): \", model_mlp_car_score_train*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abalone Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CSV.File(\"abalone\\\\abalone.data\"; header=[\"sex\", \"length\", \"diam\", \"heignt\", \"whole\", \"shucked\", \"viscera\", \"shell\", \"rings\"], types=[String, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Int]) |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = convert(Array, df[!, [:length, :diam, :heignt, :whole, :shucked, :viscera, :shell]]);\n",
    "y = convert(Array, df[!, :rings]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y.<=8].=1;\n",
    "y[y.==9].=2;\n",
    "y[y.==10].=2;\n",
    "y[y.>10].=3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = CrossValidation.train_test_split(X, y, test_size=0.30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayesian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abalone Data Naive Bayesian Classifier Training Time (Seconds): 0.000905699\n"
     ]
    }
   ],
   "source": [
    "model_baye_abalone_train_time = @elapsed begin\n",
    "model_baye_abalone = GaussianNB();\n",
    "model_baye_abalone.fit(X_train, y_train);\n",
    "end\n",
    "println(\"Abalone Data Naive Bayesian Classifier Training Time (Seconds): \", model_baye_abalone_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abalone Data Naive Bayesian Classifier Model Size (Bytes): 1053\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model_baye_abalone, \"model_baye_abalone.pkl\")\n",
    "model_baye_abalone_size = stat(\"model_baye_abalone.pkl\").size\n",
    "println(\"Abalone Data Naive Bayesian Classifier Model Size (Bytes): \", model_baye_abalone_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abalone Data Naive Bayesian Classifier Accuracy (Testing): 56.9377990430622%\n",
      "Abalone Data Naive Bayesian Classifier Testing Time (Seconds): 0.000563099\n",
      "Abalone Data Naive Bayesian Classifier Accuracy (Training): 58.94628806021211%\n"
     ]
    }
   ],
   "source": [
    "model_baye_abalone_test_time = @elapsed begin\n",
    "model_baye_abalone_score_test = model_baye_abalone.score(X_test, y_test);\n",
    "end\n",
    "model_baye_abalone_score_train = model_baye_abalone.score(X_train, y_train);\n",
    "\n",
    "println(\"Abalone Data Naive Bayesian Classifier Accuracy (Testing): \", model_baye_abalone_score_test*100,\"%\")\n",
    "println(\"Abalone Data Naive Bayesian Classifier Testing Time (Seconds): \", model_baye_abalone_test_time)\n",
    "println(\"Abalone Data Naive Bayesian Classifier Accuracy (Training): \", model_baye_abalone_score_train*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: Dict{Symbol,Any}(:max_depth => 5)\n"
     ]
    }
   ],
   "source": [
    "# Find best parameters\n",
    "\n",
    "parameters = Dict(:max_depth => 1:1:20);\n",
    "gridsearch = GridSearchCV(DecisionTreeClassifier(), parameters);\n",
    "fit!(gridsearch, X_train, y_train);\n",
    "println(\"Best parameters: $(gridsearch.best_params_)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abalone Data Decision Tree Classifier Training Time (Seconds): 0.0043471\n"
     ]
    }
   ],
   "source": [
    "model_decision_abalone_train_time = @elapsed begin\n",
    "model_decision_abalone = DecisionTreeClassifier(max_depth = gridsearch.best_params_[:max_depth]);\n",
    "model_decision_abalone.fit(X_train, y_train);\n",
    "end\n",
    "println(\"Abalone Data Decision Tree Classifier Training Time (Seconds): \", model_decision_abalone_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abalone Data Decision Tree Classifier Model Size (Bytes): 6053\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model_decision_abalone, \"model_decision_abalone.pkl\")\n",
    "model_decision_abalone_size = stat(\"model_decision_abalone.pkl\").size\n",
    "println(\"Abalone Data Decision Tree Classifier Model Size (Bytes): \", model_decision_abalone_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abalone Data Decision Tree Classifier Accuracy (Testing): 63.397129186602875%\n",
      "Abalone Data Decision Tree Classifier Testing Time (Seconds): 0.0004507\n",
      "Abalone Data Decision Tree Classifier Accuracy (Training): 67.02018474170373%\n"
     ]
    }
   ],
   "source": [
    "model_decision_abalone_test_time = @elapsed begin\n",
    "model_decision_abalone_score_test = model_decision_abalone.score(X_test, y_test);\n",
    "end\n",
    "model_decision_abalone_score_train = model_decision_abalone.score(X_train, y_train);\n",
    "\n",
    "println(\"Abalone Data Decision Tree Classifier Accuracy (Testing): \", model_decision_abalone_score_test*100,\"%\")\n",
    "println(\"Abalone Data Decision Tree Classifier Testing Time (Seconds): \", model_decision_abalone_test_time)\n",
    "println(\"Abalone Data Decision Tree Classifier Accuracy (Training): \", model_decision_abalone_score_train*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vecor Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best parameters\n",
    "\n",
    "# parameters = Dict(:kernel => [\"linear\", \"rbf\"], :gamma => [\"auto\", \"scale\"], :C => 1:5:50);\n",
    "# @suppress begin\n",
    "# gridsearch = GridSearchCV(SVC(), parameters);\n",
    "# fit!(gridsearch, X_train, y_train);\n",
    "# end\n",
    "# println(\"Best parameters: $(gridsearch.best_params_)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abalone Data Support Vector Machine Training Time (Seconds): 0.31793\n"
     ]
    }
   ],
   "source": [
    "model_svm_abalone_train_time = @elapsed begin\n",
    "model_svm_abalone = make_pipeline(StandardScaler(), SVC(gamma = \"scale\", kernel = \"rbf\", C = 36));\n",
    "model_svm_abalone.fit(X_train, y_train);\n",
    "end\n",
    "println(\"Abalone Data Support Vector Machine Training Time (Seconds): \", model_svm_abalone_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abalone Data Support Vector Machine Model Size (Bytes): 181230\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model_svm_abalone, \"model_svm_abalone.pkl\")\n",
    "model_svm_abalone_size = stat(\"model_svm_abalone.pkl\").size\n",
    "println(\"Abalone Data Support Vector Machine Model Size (Bytes): \", model_svm_abalone_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abalone Data Support Vector Machine Accuracy (Testing): 66.18819776714514%\n",
      "Abalone Data Support Vector Machine Testing Time (Seconds): 0.173649699\n",
      "Abalone Data Support Vector Machine Accuracy (Training): 68.18337324666437%\n"
     ]
    }
   ],
   "source": [
    "model_svm_abalone_test_time = @elapsed begin\n",
    "model_svm_abalone_score_test = model_svm_abalone.score(X_test, y_test);\n",
    "end\n",
    "model_svm_abalone_score_train = model_svm_abalone.score(X_train, y_train);\n",
    "\n",
    "println(\"Abalone Data Support Vector Machine Accuracy (Testing): \", model_svm_abalone_score_test*100,\"%\")\n",
    "println(\"Abalone Data Support Vector Machine Testing Time (Seconds): \", model_svm_abalone_test_time)\n",
    "println(\"Abalone Data Support Vector Machine Accuracy (Training): \", model_svm_abalone_score_train*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nerual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best parameters\n",
    "\n",
    "# parameters = Dict(:activation => [\"tanh\", \"relu\"], :alpha => 0.0001:0.0001:0.0004, :hidden_layer_sizes => 200:50:500);\n",
    "# @suppress begin\n",
    "# gridsearch = GridSearchCV(MLPClassifier(), parameters);\n",
    "# fit!(gridsearch, X_train, y_train)\n",
    "# end\n",
    "# println(\"Best parameters: $(gridsearch.best_params_)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abalone Data MLP Training Time (Seconds): 2.5378856\n"
     ]
    }
   ],
   "source": [
    "model_mlp_abalone_train_time = @elapsed begin\n",
    "model_mlp_abalone = MLPClassifier(alpha = 0.0002, activation = \"relu\", hidden_layer_sizes = 500, max_iter=300);\n",
    "model_mlp_abalone.fit(X_train, y_train);\n",
    "end\n",
    "println(\"Abalone Data MLP Training Time (Seconds): \", model_mlp_abalone_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abalone Data MLP Model Size (Bytes): 95827\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model_mlp_abalone, \"model_mlp_abalone.pkl\")\n",
    "model_mlp_abalone_size = stat(\"model_mlp_abalone.pkl\").size\n",
    "println(\"Abalone Data MLP Model Size (Bytes): \", model_mlp_abalone_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abalone Data MLP Accuracy (Testing): 65.62998405103669%\n",
      "Abalone Data MLP Testing Time (Seconds): 0.003544\n",
      "Abalone Data MLP Accuracy (Training): 65.17276770441327%\n"
     ]
    }
   ],
   "source": [
    "model_mlp_abalone_test_time = @elapsed begin\n",
    "model_mlp_abalone_score_test = model_mlp_abalone.score(X_test, y_test);\n",
    "end\n",
    "model_mlp_abalone_score_train = model_mlp_abalone.score(X_train, y_train);\n",
    "\n",
    "println(\"Abalone Data MLP Accuracy (Testing): \", model_mlp_abalone_score_test*100,\"%\")\n",
    "println(\"Abalone Data MLP Testing Time (Seconds): \", model_mlp_abalone_test_time)\n",
    "println(\"Abalone Data MLP Accuracy (Training): \", model_mlp_abalone_score_train*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Madelon Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train = CSV.File(\"madelon\\\\madelon_train.data\"; header = false) |> DataFrame;\n",
    "df_y_train = CSV.File(\"madelon\\\\madelon_train.labels\"; header = false) |> DataFrame;\n",
    "df_X_train = df_X_train[:, Not(501)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_test = CSV.File(\"madelon\\\\madelon_valid.data\"; header = false) |> DataFrame;\n",
    "df_y_test = CSV.File(\"madelon\\\\madelon_valid.labels\"; header = false) |> DataFrame;\n",
    "df_X_test = df_X_test[:, Not(501)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = convert(Array, df_X_train);\n",
    "y_train = convert(Array, df_y_train);\n",
    "\n",
    "X_test = convert(Array, df_X_test);\n",
    "y_test = convert(Array, df_y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayesian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madelon Data Naive Bayesian Classifier Training Time (Seconds): 0.0233316\n"
     ]
    }
   ],
   "source": [
    "model_baye_madelon_train_time = @elapsed begin\n",
    "model_baye_madelon = make_pipeline(VarianceThreshold(threshold = 50.0), GaussianNB());\n",
    "model_baye_madelon.fit(X_train, y_train);\n",
    "end\n",
    "println(\"Madelon Data Naive Bayesian Classifier Training Time (Seconds): \", model_baye_madelon_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madelon Data Naive Bayesian Classifier Model Size (Bytes): 18540\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model_baye_madelon, \"model_baye_madelon.pkl\")\n",
    "model_baye_madelon_size = stat(\"model_baye_madelon.pkl\").size\n",
    "println(\"Madelon Data Naive Bayesian Classifier Model Size (Bytes): \", model_baye_madelon_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madelon Data Naive Bayesian Classifier Accuracy (Testing): 60.0%\n",
      "Madelon Data Naive Bayesian Classifier Testing Time (Seconds): 0.0048711\n",
      "Madelon Data Naive Bayesian Classifier Accuracy (Training): 70.25%\n"
     ]
    }
   ],
   "source": [
    "model_baye_madelon_test_time = @elapsed begin\n",
    "model_baye_madelon_score_test = model_baye_madelon.score(X_test, y_test);\n",
    "end\n",
    "model_baye_madelon_score_train = model_baye_madelon.score(X_train, y_train);\n",
    "\n",
    "println(\"Madelon Data Naive Bayesian Classifier Accuracy (Testing): \", model_baye_madelon_score_test*100,\"%\")\n",
    "println(\"Madelon Data Naive Bayesian Classifier Testing Time (Seconds): \", model_baye_madelon_test_time)\n",
    "println(\"Madelon Data Naive Bayesian Classifier Accuracy (Training): \", model_baye_madelon_score_train*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best parameters\n",
    "\n",
    "# parameters = Dict(:max_depth => 1:1:20);\n",
    "# gridsearch = GridSearchCV(DecisionTreeClassifier(), parameters);\n",
    "# fit!(gridsearch, X_train, y_train);\n",
    "# println(\"Best parameters: $(gridsearch.best_params_)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madelon Data Decision Tree Classifier Training Time (Seconds): 0.2127508\n"
     ]
    }
   ],
   "source": [
    "model_decision_madelon_train_time = @elapsed begin\n",
    "model_decision_madelon = DecisionTreeClassifier(max_depth = 6);\n",
    "model_decision_madelon.fit(X_train, y_train);\n",
    "end\n",
    "println(\"Madelon Data Decision Tree Classifier Training Time (Seconds): \", model_decision_madelon_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madelon Data Decision Tree Classifier Model Size (Bytes): 9161\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model_decision_madelon, \"model_decision_madelon.pkl\")\n",
    "model_decision_madelon_size = stat(\"model_decision_madelon.pkl\").size\n",
    "println(\"Madelon Data Decision Tree Classifier Model Size (Bytes): \", model_decision_madelon_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madelon Data Decision Tree Classifier Accuracy (Testing): 79.5%\n",
      "Madelon Data Decision Tree Classifier Testing Time (Seconds): 0.0055438\n",
      "Madelon Data Decision Tree Classifier Accuracy (Training): 91.10000000000001%\n"
     ]
    }
   ],
   "source": [
    "model_decision_madelon_test_time = @elapsed begin\n",
    "model_decision_madelon_score_test = model_decision_madelon.score(X_test, y_test);\n",
    "end\n",
    "model_decision_madelon_score_train = model_decision_madelon.score(X_train, y_train);\n",
    "\n",
    "println(\"Madelon Data Decision Tree Classifier Accuracy (Testing): \", model_decision_madelon_score_test*100,\"%\")\n",
    "println(\"Madelon Data Decision Tree Classifier Testing Time (Seconds): \", model_decision_madelon_test_time)\n",
    "println(\"Madelon Data Decision Tree Classifier Accuracy (Training): \", model_decision_madelon_score_train*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best parameters\n",
    "\n",
    "# parameters = Dict(:kernel => [\"linear\", \"rbf\"], :gamma => [\"auto\", \"scale\"], :C => 1:5:50);\n",
    "# @suppress begin\n",
    "# gridsearch = GridSearchCV(SVC(), parameters);\n",
    "# fit!(gridsearch, X_train, y_train);\n",
    "# end\n",
    "# println(\"Best parameters: $(gridsearch.best_params_)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madelon Data Support Vector Machine Training Time (Seconds): 0.5310343\n"
     ]
    }
   ],
   "source": [
    "model_svm_madelon_train_time = @elapsed begin\n",
    "model_svm_madelon = SVC(gamma = \"scale\", kernel = \"rbf\", C = 25);\n",
    "model_svm_madelon.fit(X_train, y_train);\n",
    "end\n",
    "println(\"Madelon Data Support Vector Machine Training Time (Seconds): \", model_svm_madelon_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madelon Data Support Vector Machine Model Size (Bytes): 9161\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model_svm_madelon, \"model_svm_madelon.pkl\")\n",
    "model_svm_madelon_size = stat(\"model_svm_madelon.pkl\").size\n",
    "println(\"Madelon Data Support Vector Machine Model Size (Bytes): \", model_decision_madelon_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madelon Data Support Vector Machine Accuracy (Testing): 69.66666666666667%\n",
      "Madelon Data Support Vector Machine Testing Time (Seconds): 0.286985501\n",
      "Madelon Data Support Vector Machine Accuracy (Training): 100.0%\n"
     ]
    }
   ],
   "source": [
    "model_svm_madelon_test_time = @elapsed begin\n",
    "model_svm_madelon_score_test = model_svm_madelon.score(X_test, y_test);\n",
    "end\n",
    "model_svm_madelon_score_train = model_svm_madelon.score(X_train, y_train);\n",
    "\n",
    "println(\"Madelon Data Support Vector Machine Accuracy (Testing): \", model_svm_madelon_score_test*100,\"%\")\n",
    "println(\"Madelon Data Support Vector Machine Testing Time (Seconds): \", model_svm_madelon_test_time)\n",
    "println(\"Madelon Data Support Vector Machine Accuracy (Training): \", model_svm_madelon_score_train*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best parameters\n",
    "\n",
    "# parameters = Dict(:activation => [\"tanh\", \"relu\"], :alpha => 0.0001:0.0001:0.0004, :hidden_layer_sizes => 200:50:500);\n",
    "# @suppress begin\n",
    "# gridsearch = GridSearchCV(MLPClassifier(), parameters);\n",
    "# fit!(gridsearch, X_train, y_train)\n",
    "# end\n",
    "# println(\"Best parameters: $(gridsearch.best_params_)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madelon Data MLP Training Time (Seconds): 1.291116401\n"
     ]
    }
   ],
   "source": [
    "model_mlp_madelon_train_time = @elapsed begin\n",
    "model_mlp_madelon = MLPClassifier(alpha = 0.0001, activation = \"relu\", hidden_layer_sizes = 300, max_iter=300);\n",
    "model_mlp_madelon.fit(X_train, y_train);\n",
    "end\n",
    "println(\"Madelon Data MLP Training Time (Seconds): \", model_mlp_madelon_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madelon Data MLP Model Size (Bytes): 4824407\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model_mlp_madelon, \"model_mlp_madelon.pkl\")\n",
    "model_mlp_madelon_size = stat(\"model_mlp_madelon.pkl\").size\n",
    "println(\"Madelon Data MLP Model Size (Bytes): \", model_mlp_madelon_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madelon Data MLP Accuracy (Testing): 50.0%\n",
      "Madelon Data MLP Testing Time (Seconds): 0.006724301\n",
      "Madelon Data MLP Accuracy (Training): 50.0%\n"
     ]
    }
   ],
   "source": [
    "model_mlp_madelon_test_time = @elapsed begin\n",
    "model_mlp_madelon_score_test = model_mlp_madelon.score(X_test, y_test);\n",
    "end\n",
    "model_mlp_madelon_score_train = model_mlp_madelon.score(X_train, y_train);\n",
    "\n",
    "println(\"Madelon Data MLP Accuracy (Testing): \", model_mlp_madelon_score_test*100,\"%\")\n",
    "println(\"Madelon Data MLP Testing Time (Seconds): \", model_mlp_madelon_test_time)\n",
    "println(\"Madelon Data MLP Accuracy (Training): \", model_mlp_madelon_score_train*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDD Cup 1999 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CSV.File(\"kddcup\\\\kddcup.data_10_percent_corrected\"; header = false) |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = df[:, Not(42)];\n",
    "y_df = df[:, 42];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = convert(Array, X_df);\n",
    "y = convert(Array, y_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y.!=\"normal.\"].= \"malware.\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder();\n",
    "onehot_encoded = onehot_encoder.fit_transform(X[:, 2:4]);\n",
    "onehot_encoded = onehot_encoded.toarray();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_df = DataFrame(onehot_encoded);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = X_df[:, Not(2:4)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = [one_df X_df];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = convert(Array, X_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = CrossValidation.train_test_split(X, y, test_size=0.30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayesian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kdd Data Naive Bayesian Classifier Training Time (Seconds): 0.761639699\n"
     ]
    }
   ],
   "source": [
    "model_baye_kdd_train_time = @elapsed begin\n",
    "model_baye_kdd = GaussianNB();\n",
    "model_baye_kdd.fit(X_train, y_train);\n",
    "end\n",
    "println(\"Kdd Data Naive Bayesian Classifier Training Time (Seconds): \", model_baye_kdd_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kdd Data Naive Bayesian Classifier Model Size (Bytes): 4511\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model_baye_kdd, \"model_baye_kdd.pkl\")\n",
    "model_baye_kdd_size = stat(\"model_baye_kdd.pkl\").size\n",
    "println(\"Kdd Data Naive Bayesian Classifier Model Size (Bytes): \", model_baye_kdd_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kdd Data Naive Bayesian Classifier Accuracy (Testing): 91.9875579426073%\n",
      "Kdd Data Naive Bayesian Classifier Testing Time (Seconds): 0.4493737\n",
      "Kdd Data Naive Bayesian Classifier Accuracy (Training): 91.92918736661905%\n"
     ]
    }
   ],
   "source": [
    "model_baye_kdd_test_time = @elapsed begin\n",
    "model_baye_kdd_score_test = model_baye_kdd.score(X_test, y_test);\n",
    "end\n",
    "model_baye_kdd_score_train = model_baye_kdd.score(X_train, y_train);\n",
    "\n",
    "println(\"Kdd Data Naive Bayesian Classifier Accuracy (Testing): \", model_baye_kdd_score_test*100,\"%\")\n",
    "println(\"Kdd Data Naive Bayesian Classifier Testing Time (Seconds): \", model_baye_kdd_test_time)\n",
    "println(\"Kdd Data Naive Bayesian Classifier Accuracy (Training): \", model_baye_kdd_score_train*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best parameters\n",
    "\n",
    "# parameters = Dict(:max_depth => 1:1:20);\n",
    "# gridsearch = GridSearchCV(DecisionTreeClassifier(), parameters);\n",
    "# fit!(gridsearch, X_train, y_train);\n",
    "# println(\"Best parameters: $(gridsearch.best_params_)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kdd Data Decision Tree Classifier Training Time (Seconds): 1.9182991\n"
     ]
    }
   ],
   "source": [
    "model_decision_kdd_train_time = @elapsed begin\n",
    "model_decision_kdd = DecisionTreeClassifier(max_depth = 17);\n",
    "model_decision_kdd.fit(X_train, y_train);\n",
    "end\n",
    "println(\"Kdd Data Decision Tree Classifier Training Time (Seconds): \", model_decision_kdd_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kdd Data Decision Tree Classifier Model Size (Bytes): 17729\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model_decision_kdd, \"model_decision_kdd.pkl\")\n",
    "model_decision_kdd_size = stat(\"model_decision_kdd.pkl\").size\n",
    "println(\"Kdd Data Decision Tree Classifier Model Size (Bytes): \", model_decision_kdd_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kdd Data Decision Tree Classifier Accuracy (Testing): 99.96896232971451%\n",
      "Kdd Data Decision Tree Classifier Testing Time (Seconds): 0.1412056\n",
      "Kdd Data Decision Tree Classifier Accuracy (Training): 99.98698722434604%\n"
     ]
    }
   ],
   "source": [
    "model_decision_kdd_test_time = @elapsed begin\n",
    "model_decision_kdd_score_test = model_decision_kdd.score(X_test, y_test);\n",
    "end\n",
    "model_decision_kdd_score_train = model_decision_kdd.score(X_train, y_train);\n",
    "\n",
    "println(\"Kdd Data Decision Tree Classifier Accuracy (Testing): \", model_decision_kdd_score_test*100,\"%\")\n",
    "println(\"Kdd Data Decision Tree Classifier Testing Time (Seconds): \", model_decision_kdd_test_time)\n",
    "println(\"Kdd Data Decision Tree Classifier Accuracy (Training): \", model_decision_kdd_score_train*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best parameters\n",
    "\n",
    "# parameters = Dict(:pca__n_components => 10:10:50);\n",
    "# @suppress begin\n",
    "# gridsearch = GridSearchCV(make_pipeline(PCA(), LinearSVC()), parameters);\n",
    "# fit!(gridsearch, X_train, y_train);\n",
    "# end\n",
    "# println(\"Best parameters: $(gridsearch.best_params_)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kdd Data Support Vector Machine Training Time (Seconds): 92.9914577\n"
     ]
    }
   ],
   "source": [
    "model_svm_kdd_train_time = @elapsed begin\n",
    "model_svm_kdd = make_pipeline(PCA(n_components = 40), LinearSVC());\n",
    "model_svm_kdd.fit(X_train, y_train);\n",
    "end\n",
    "println(\"Kdd Data Support Vector Machine Training Time (Seconds): \", model_svm_kdd_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kdd Data Support Vector Machine Model Size (Bytes): 41414\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model_svm_kdd, \"model_svm_kdd.pkl\")\n",
    "model_svm_kdd_size = stat(\"model_svm_kdd.pkl\").size\n",
    "println(\"Kdd Data Support Vector Machine Model Size (Bytes): \", model_svm_kdd_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kdd Data Support Vector Machine Accuracy (Testing): 98.58711127004798%\n",
      "Kdd Data Support Vector Machine Testing Time (Seconds): 0.2020244\n",
      "Kdd Data Support Vector Machine Accuracy (Training): 98.49369892485555%\n"
     ]
    }
   ],
   "source": [
    "model_svm_kdd_test_time = @elapsed begin\n",
    "model_svm_kdd_score_test = model_svm_kdd.score(X_test, y_test);\n",
    "end\n",
    "model_svm_kdd_score_train = model_svm_kdd.score(X_train, y_train);\n",
    "\n",
    "println(\"Kdd Data Support Vector Machine Accuracy (Testing): \", model_svm_kdd_score_test*100,\"%\")\n",
    "println(\"Kdd Data Support Vector Machine Testing Time (Seconds): \", model_svm_kdd_test_time)\n",
    "println(\"Kdd Data Support Vector Machine Accuracy (Training): \", model_svm_kdd_score_train*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best parameters\n",
    "\n",
    "# parameters = Dict(:alpha => 0.0001:0.0001:0.0004, :hidden_layer_sizes => 300:50:500);\n",
    "# @suppress begin\n",
    "# gridsearch = GridSearchCV(MLPClassifier(), parameters);\n",
    "# fit!(gridsearch, X_train, y_train)\n",
    "# end\n",
    "# println(\"Best parameters: $(gridsearch.best_params_)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kdd Data MLP Training Time (Seconds): 65.7870003\n"
     ]
    }
   ],
   "source": [
    "model_mlp_kdd_train_time = @elapsed begin\n",
    "model_mlp_kdd = make_pipeline(PCA(n_components = 40), MLPClassifier(alpha = 0.0001, activation = \"relu\", hidden_layer_sizes = 300, max_iter=300));\n",
    "model_mlp_kdd.fit(X_train, y_train);\n",
    "end\n",
    "println(\"Kdd Data MLP Training Time (Seconds): \", model_mlp_kdd_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kdd Data MLP Model Size (Bytes): 449168\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model_mlp_kdd, \"model_mlp_kdd.pkl\")\n",
    "model_mlp_kdd_size = stat(\"model_mlp_kdd.pkl\").size\n",
    "println(\"Kdd Data MLP Model Size (Bytes): \", model_mlp_kdd_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kdd Data MLP Accuracy (Testing): 99.71256418387794%\n",
      "Kdd Data MLP Testing Time (Seconds): 0.413835199\n",
      "Kdd Data MLP Accuracy (Training): 99.70735713418196%\n"
     ]
    }
   ],
   "source": [
    "model_mlp_kdd_test_time = @elapsed begin\n",
    "model_mlp_kdd_score_test = model_mlp_kdd.score(X_test, y_test);\n",
    "end\n",
    "model_mlp_kdd_score_train = model_mlp_kdd.score(X_train, y_train);\n",
    "\n",
    "println(\"Kdd Data MLP Accuracy (Testing): \", model_mlp_kdd_score_test*100,\"%\")\n",
    "println(\"Kdd Data MLP Testing Time (Seconds): \", model_mlp_kdd_test_time)\n",
    "println(\"Kdd Data MLP Accuracy (Training): \", model_mlp_kdd_score_train*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"Data Set\" \"Model\" \"Train Time\" \"Test Time\" \"Train Accuracy\" \"Test Accuracy\" \"Model Size\"\n",
    "           \"\" \"\"  \"[s]\"        \"[s]\"       \"[%]\"            \"[%]\"           \"[Bytes]\"];\n",
    "tabulation = [\n",
    "\"Car\" \"Naive Bayesian\" model_baye_car_train_time model_baye_car_test_time model_baye_car_score_train*100 model_baye_car_score_test*100 model_baye_car_size\n",
    "\"Car\" \"Decision Tree\" model_decision_car_train_time model_decision_car_test_time model_decision_car_score_train*100 model_decision_car_score_test*100 model_decision_car_size\n",
    "\"Car\" \"SVM Vector Machine\" model_svm_car_train_time model_svm_car_test_time model_svm_car_score_train*100 model_svm_car_score_test*100 model_svm_car_size\n",
    "\"Car\" \"Multilayer Perceptron\" model_mlp_car_train_time model_mlp_car_test_time model_mlp_car_score_train*100 model_mlp_car_score_test*100 model_mlp_car_size\n",
    "\"\" \"\" \"\" \"\" \"\" \"\" \"\"\n",
    "\"Abalone\" \"Naive Bayesian\" model_baye_abalone_train_time model_baye_abalone_test_time model_baye_abalone_score_train*100 model_baye_abalone_score_test*100 model_baye_abalone_size\n",
    "\"Abalone\" \"Decision Tree\" model_decision_abalone_train_time model_decision_abalone_test_time model_decision_abalone_score_train*100 model_decision_abalone_score_test*100 model_decision_abalone_size\n",
    "\"Abalone\" \"SVM Vector Machine\" model_svm_abalone_train_time model_svm_abalone_test_time model_svm_abalone_score_train*100 model_svm_abalone_score_test*100 model_svm_abalone_size\n",
    "\"Abalone\" \"Multilayer Perceptron\" model_mlp_abalone_train_time model_mlp_abalone_test_time model_mlp_abalone_score_train*100 model_mlp_abalone_score_test*100 model_mlp_abalone_size\n",
    "\"\" \"\" \"\" \"\" \"\" \"\" \"\"\n",
    "\"Madelon\" \"Naive Bayesian\" model_baye_madelon_train_time model_baye_madelon_test_time model_baye_madelon_score_train*100 model_baye_madelon_score_test*100 model_baye_madelon_size\n",
    "\"Madelon\" \"Decision Tree\" model_decision_madelon_train_time model_decision_madelon_test_time model_decision_madelon_score_train*100 model_decision_madelon_score_test*100 model_decision_madelon_size\n",
    "\"Madelon\" \"SVM Vector Machine\" model_svm_madelon_train_time model_svm_madelon_test_time model_svm_madelon_score_train*100 model_svm_madelon_score_test*100 model_svm_madelon_size\n",
    "\"Madelon\" \"Multilayer Perceptron\" model_mlp_madelon_train_time model_mlp_madelon_test_time model_mlp_madelon_score_train*100 model_mlp_madelon_score_test*100 model_mlp_madelon_size\n",
    "\"\" \"\" \"\" \"\" \"\" \"\" \"\"\n",
    "\"Kdd\" \"Naive Bayesian\" model_baye_kdd_train_time model_baye_kdd_test_time model_baye_kdd_score_train*100 model_baye_kdd_score_test*100 model_baye_kdd_size\n",
    "\"Kdd\" \"Decision Tree\" model_decision_kdd_train_time model_decision_kdd_test_time model_decision_kdd_score_train*100 model_decision_kdd_score_test*100 model_decision_kdd_size\n",
    "\"Kdd\" \"SVM Vector Machine\" model_svm_kdd_train_time model_svm_kdd_test_time model_svm_kdd_score_train*100 model_svm_kdd_score_test*100 model_svm_kdd_size\n",
    "\"Kdd\" \"Multilayer Perceptron\" model_mlp_kdd_train_time model_mlp_kdd_test_time model_mlp_kdd_score_train*100 model_mlp_kdd_score_test*100 model_mlp_kdd_size\n",
    "\n",
    "];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────┬───────────────────────┬─────────────┬─────────────┬────────────────┬───────────────┬────────────┐\n",
      "│\u001b[1m Data Set \u001b[0m│\u001b[1m                 Model \u001b[0m│\u001b[1m  Train Time \u001b[0m│\u001b[1m   Test Time \u001b[0m│\u001b[1m Train Accuracy \u001b[0m│\u001b[1m Test Accuracy \u001b[0m│\u001b[1m Model Size \u001b[0m│\n",
      "│\u001b[90m          \u001b[0m│\u001b[90m                       \u001b[0m│\u001b[90m         [s] \u001b[0m│\u001b[90m         [s] \u001b[0m│\u001b[90m            [%] \u001b[0m│\u001b[90m           [%] \u001b[0m│\u001b[90m    [Bytes] \u001b[0m│\n",
      "├──────────┼───────────────────────┼─────────────┼─────────────┼────────────────┼───────────────┼────────────┤\n",
      "│      Car │        Naive Bayesian │   0.0013208 │   0.0007432 │        79.9007 │       81.1175 │       2127 │\n",
      "│      Car │         Decision Tree │   0.0014408 │ 0.000576501 │         98.263 │       92.8709 │      13665 │\n",
      "│      Car │    SVM Vector Machine │   0.0416932 │   0.0224784 │          100.0 │       99.2293 │     117902 │\n",
      "│      Car │ Multilayer Perceptron │     2.22976 │   0.0022574 │          100.0 │        99.422 │     343098 │\n",
      "│          │                       │             │             │                │               │            │\n",
      "│  Abalone │        Naive Bayesian │ 0.000905699 │ 0.000563099 │        58.9463 │       56.9378 │       1053 │\n",
      "│  Abalone │         Decision Tree │   0.0043471 │   0.0004507 │        67.0202 │       63.3971 │       6053 │\n",
      "│  Abalone │    SVM Vector Machine │     0.31793 │     0.17365 │        68.1834 │       66.1882 │     181230 │\n",
      "│  Abalone │ Multilayer Perceptron │     2.53789 │    0.003544 │        65.1728 │         65.63 │      95827 │\n",
      "│          │                       │             │             │                │               │            │\n",
      "│  Madelon │        Naive Bayesian │   0.0233316 │   0.0048711 │          70.25 │          60.0 │      18540 │\n",
      "│  Madelon │         Decision Tree │    0.212751 │   0.0055438 │           91.1 │          79.5 │       9161 │\n",
      "│  Madelon │    SVM Vector Machine │    0.531034 │    0.286986 │          100.0 │       69.6667 │    7579030 │\n",
      "│  Madelon │ Multilayer Perceptron │     1.29112 │   0.0067243 │           50.0 │          50.0 │    4824407 │\n",
      "│          │                       │             │             │                │               │            │\n",
      "│      Kdd │        Naive Bayesian │     0.76164 │    0.449374 │        91.9292 │       91.9876 │       4511 │\n",
      "│      Kdd │         Decision Tree │      1.9183 │    0.141206 │         99.987 │        99.969 │      17729 │\n",
      "│      Kdd │    SVM Vector Machine │     92.9915 │    0.202024 │        98.4937 │       98.5871 │      41414 │\n",
      "│      Kdd │ Multilayer Perceptron │      65.787 │    0.413835 │        99.7074 │       99.7126 │     449168 │\n",
      "└──────────┴───────────────────────┴─────────────┴─────────────┴────────────────┴───────────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "final_data = pretty_table(tabulation, header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "## 1. This entire notebook needs to be run for the table above to be filled in with data. Running the notebook will take roughly 5 minutes. \n",
    "## 2. Recommended to run this notebook in a folder so the dumped models are contained and can be deleted easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car Data Set\n",
    "\n",
    "### Data Arrangement\n",
    "I used one hot encoding on the entire data set to convert the strings to numerical values.\n",
    "\n",
    "### Naive Bayesian Classifier\n",
    "1. The data was partitioned using a 70-30 split for training and testing respecively. The function \"train_test_split\" was used to acheive this.\n",
    "2. I tuned no parameters for this classifier.\n",
    "3. The model performed with an accuracy of ~80.5% on the training data and an accuracy of ~80.1% on the testing data.\n",
    "4. This model is relatively small with a size of 2127 bytes.\n",
    "5. It took ~0.0007376 seconds to test the data.\n",
    "6. It took ~0.0012337 seconds to train the model.\n",
    "\n",
    "### Decision Trees\n",
    "1. The data was partitioned using a 70-30 split for training and testing respecively. The function \"train_test_split\" was used to acheive this.\n",
    "2. I tuned the max depth parameter for this classifier. I found the optimal max depth using the gridsearchcv function.\n",
    "3. The model performed with an accuracy of ~99.9% on the training data and an accuracy of ~97.3% on the testing data.\n",
    "4. This model is relatively small with a size of 15953 bytes.\n",
    "5. It took ~0.0005928 seconds to test the data.\n",
    "6. It took ~0.0014793 seconds to train the model.\n",
    "\n",
    "### Support Vector Machine\n",
    "1. The data was partitioned using a 70-30 split for training and testing respecively. The function \"train_test_split\" was used to acheive this.\n",
    "2. I tuned the kernel, gamma, and C value parameters for this classifier. I found the optimal combination using the gridsearchcv function. I also used a pipeline which applied a standard scaler on the data before passing it to the SVC model.\n",
    "3. The model performed with an accuracy of ~99.4% on the training data and an accuracy of ~100% on the testing data.\n",
    "4. This model has a size of 117902 bytes.\n",
    "5. It took ~0.0216899 seconds to test the data.\n",
    "6. It took ~0.0419913 seconds to train the model.\n",
    "\n",
    "### Neural Networks (MLP)\n",
    "1. The data was partitioned using a 70-30 split for training and testing respecively. The function \"train_test_split\" was used to acheive this.\n",
    "2. I tuned the activation, alpha, and hidden layers parameters for this classifier. I found the optimal combination using the gridsearchcv function.\n",
    "3. The model performed with an accuracy of ~99.4% on the training data and an accuracy of ~100% on the testing data.\n",
    "4. This model is larger than the others for this data set with a size of 343098 bytes.\n",
    "5. It took ~0.001791 seconds to test the data.\n",
    "6. It took ~2.19969 seconds to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abalone Data Set\n",
    "\n",
    "### Data Arrangement\n",
    "I reclassifed the rings into three sections: 1-8, 9 and 10, and 11+. This is the same method as what was stated in the \"Past Usage\" section of the data, and I acheived similar results which can be seen below.\n",
    "\n",
    "### Naive Bayesian Classifier\n",
    "1. The data was partitioned using a 70-30 split for training and testing respecively. The function \"train_test_split\" was used to acheive this.\n",
    "2. I tuned no parameters for this classifier.\n",
    "3. The model performed with an accuracy of ~57.7% on the training data and an accuracy of ~58.7% on the testing data.\n",
    "4. This model is extremely small with a size of 1053 bytes.\n",
    "5. It took ~0.0005545 seconds to test the data.\n",
    "6. It took ~0.000911101 seconds to train the model.\n",
    "\n",
    "### Decision Trees\n",
    "1. The data was partitioned using a 70-30 split for training and testing respecively. The function \"train_test_split\" was used to acheive this.\n",
    "2. I tuned the max depth parameter for this classifier. I found the optimal max depth using the gridsearchcv function.\n",
    "3. The model performed with an accuracy of ~63.8% on the training data and an accuracy of ~61.8% on the testing data.\n",
    "4. This model is relatively small with a size of 3653 bytes.\n",
    "5. It took ~0.0004264 seconds to test the data.\n",
    "6. It took ~0.0035288 seconds to train the model.\n",
    "\n",
    "### Support Vector Machine\n",
    "1. The data was partitioned using a 70-30 split for training and testing respecively. The function \"train_test_split\" was used to acheive this.\n",
    "2. I tuned the kernel, gamma, and C value parameters for this classifier. I found the optimal combination using the gridsearchcv function. I also used a pipeline which applied a standard scaler on the data before passing it to the SVC model.\n",
    "3. The model performed with an accuracy of ~66.9% on the training data and an accuracy of ~67% on the testing data.\n",
    "4. This model has a size of 185738 bytes.\n",
    "5. It took ~0.178399 seconds to test the data.\n",
    "6. It took ~0.338481 seconds to train the model.\n",
    "\n",
    "### Neural Networks (MLP)\n",
    "1. The data was partitioned using a 70-30 split for training and testing respecively. The function \"train_test_split\" was used to acheive this.\n",
    "2. I tuned the activation, alpha, and hidden layers parameters for this classifier. I found the optimal combination using the gridsearchcv function.\n",
    "3. The model performed with an accuracy of ~65.4% on the training data and an accuracy of ~66.5% on the testing data.\n",
    "4. This model is larger than the others for this data set with a size of 115482 bytes.\n",
    "5. It took ~0.0036485 seconds to test the data.\n",
    "6. It took ~3.47367 seconds to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Madelon Data Set\n",
    "\n",
    "### Naive Bayesian Classifier\n",
    "1. The data was pre-partitioned for training and testing.\n",
    "2. I tuned no parameters for this classifier, but I did use a pipeline which applied the variance threshold feature selection on the data prior to passing the data into the model.\n",
    "3. The model performed with an accuracy of ~70.3% on the training data and an accuracy of ~60.0% on the testing data.\n",
    "4. This model has a size of 18540 bytes.\n",
    "5. It took ~0.0050195 seconds to test the data.\n",
    "6. It took ~0.0228978 seconds to train the model.\n",
    "\n",
    "### Decision Trees\n",
    "1. The data was partitioned using a 70-30 split for training and testing respecively. The function \"train_test_split\" was used to acheive this.\n",
    "2. I tuned the max depth parameter for this classifier. I found the optimal max depth using the gridsearchcv function.\n",
    "3. The model performed with an accuracy of ~91.2 % on the training data and an accuracy of ~80.2% on the testing data.\n",
    "4. This model is smaller than the bayesion model with a size of 9305 bytes.\n",
    "5. It took ~0.0011152 seconds to test the data.\n",
    "6. It took ~0.212331 seconds to train the model.\n",
    "\n",
    "### Support Vector Machine\n",
    "1. The data was partitioned using a 70-30 split for training and testing respecively. The function \"train_test_split\" was used to acheive this.\n",
    "2. I tuned the kernel, gamma, and C value parameters for this classifier. I found the optimal combination using the gridsearchcv function.\n",
    "3. The model performed with an accuracy of ~100% on the training data and an accuracy of ~69.7% on the testing data.\n",
    "4. This model is the largest out of every other in this assignment with a size of 7579106 bytes.\n",
    "5. It took ~0.274302 seconds to test the data.\n",
    "6. It took ~0.519139 seconds to train the model.\n",
    "\n",
    "### Neural Networks (MLP)\n",
    "1. The data was partitioned using a 70-30 split for training and testing respecively. The function \"train_test_split\" was used to acheive this.\n",
    "2. I tuned the activation, alpha, and hidden layers parameters for this classifier. I found the optimal combination using the gridsearchcv function.\n",
    "3. The model performed with an accuracy of ~50.0% on the training data and an accuracy of ~50.0% on the testing data.\n",
    "4. This model is also one of the largest in the assignment with a size of 4824465 bytes.\n",
    "5. It took ~0.0035611 seconds to test the data.\n",
    "6. It took ~1.30549 seconds to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kdd Data Set\n",
    "\n",
    "### Data Arrangement\n",
    "I changed this into a binary classification problem with normal traffic remaining normal, and any form of attack as malware. The model attemtps to determine if the incoming traffic is normal or malware which theoretically should increase accuracy as there is less classes to discern from, but in practice the model performed well on both. I also used one hot encoding on the string data entries to convert them to numerical values. Finally, I used the 10 percent version of the data for everything as the full dataset was taking a significant amount of time to run.\n",
    "\n",
    "### Naive Bayesian Classifier\n",
    "1. The data was partitioned using a 70-30 split for training and testing respecively. The function \"train_test_split\" was used to acheive this.\n",
    "2. I tuned no parameters for this classifier.\n",
    "3. The model performed with an accuracy of ~91.6% on the training data and an accuracy of ~91.5% on the testing data.\n",
    "4. This model is relatively small with a size of 4511 bytes.\n",
    "5. It took ~0.39356 seconds to test the data.\n",
    "6. It took ~0.764164 seconds to train the model.\n",
    "\n",
    "### Decision Trees\n",
    "1. The data was partitioned using a 70-30 split for training and testing respecively. The function \"train_test_split\" was used to acheive this.\n",
    "2. I tuned the max depth parameter for this classifier. I found the optimal max depth using the gridsearchcv function.\n",
    "3. The model performed with an accuracy of ~99.9% on the training data and an accuracy of ~99.9% on the testing data.\n",
    "4. This model is still relatively small with a size of 17441 bytes.\n",
    "5. It took ~0.144964 seconds to test the data.\n",
    "6. It took ~1.85097 seconds to train the model.\n",
    "\n",
    "### Support Vector Machine\n",
    "1. The data was partitioned using a 70-30 split for training and testing respecively. The function \"train_test_split\" was used to acheive this.\n",
    "2. I tuned the kernel, gamma, and C value parameters for this classifier. I found the optimal combination using the gridsearchcv function. I also used a pipeline which applied a PCA for dimensionality reduction on the data before passing it to the SVC model.\n",
    "3. The model performed with an accuracy of ~99.9% on the training data and an accuracy of ~99.0% on the testing data.\n",
    "4. This model has a size of 41414 bytes.\n",
    "5. It took ~0.179327 seconds to test the data.\n",
    "6. It took ~86.3749 seconds to train the model.\n",
    "\n",
    "### Neural Networks (MLP)\n",
    "1. The data was partitioned using a 70-30 split for training and testing respecively. The function \"train_test_split\" was used to acheive this.\n",
    "2. I tuned the activation, alpha, and hidden layers parameters for this classifier. I found the optimal combination using the gridsearchcv function. I also used a pipeline which applied a PCA for dimensionality reduction on the data before passing it to the SVC model.\n",
    "3. The model performed with an accuracy of ~98.8% on the training data and an accuracy of 98.8% on the testing data.\n",
    "4. This model is larger than the others for this data set with a size of 449168 bytes.\n",
    "5. It took ~0.455765 seconds to test the data.\n",
    "6. It took ~35.2327 seconds to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia (8 threads) 1.5.3",
   "language": "julia",
   "name": "julia-(8-threads)-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
